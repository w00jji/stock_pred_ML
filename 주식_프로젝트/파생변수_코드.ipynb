{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8136cf16-5323-4eea-8ce6-a9e4e119786c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'KOSDAK.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 8\u001b[0m kosdak \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKOSDAK.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m kosdak\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'KOSDAK.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kosdak = pd.read_csv('KOSDAK.csv')\n",
    "kosdak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f9a35-d333-4864-8b1e-54267002eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "krx = pd.read_excel('krx/krx.xlsx')\n",
    "krx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f8ffd-18cf-4914-8db0-2aa8fea636b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# 데이터프레임을 Code 컬럼을 기준으로 병합\n",
    "merged_df = pd.merge(kosdak, krx, on='Code', how='inner')\n",
    "\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979e630-2830-43b1-817c-c6fb3f3f76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Name_x'를 'Name'으로 이름 변경\n",
    "merged_df.rename(columns={'Name_x': 'Name'}, inplace=True)\n",
    "\n",
    "# 'Name_y' 컬럼 삭제\n",
    "merged_df.drop(columns=['Name_y'], inplace=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd5136-a590-43f6-9f65-74ea60f12ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병합된 데이터프레임을 KOSDAK.csv 파일로 저장\n",
    "merged_df.to_csv('KOSDAK_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f5c78-7399-4652-9b03-cac74a7d76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "KOSDAK = pd.read_csv('KOSDAK_merged.csv')\n",
    "KOSDAK.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5dcf5-cd57-4e67-bd3e-6c0c5af784e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KOSDAK.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000128bd-b028-4daf-a428-ebb1c621b9ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KOSDAK.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a27de-2014-45f8-8328-65def154db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PER 15~20 사이\n",
    "# ROE 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8bf1b-f2cb-44a5-b106-1ce37bc27dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "KOSDAK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade2901-640f-4c1e-b598-9535e9a07cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "97/1746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10c15e-9ee2-4d2e-af70-39c3c03a5db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치가 있는 모든 행 제거\n",
    "KOSDAK_clean = KOSDAK.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35e2f1-d10e-4105-a868-9bce301c247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "KOSDAK_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644763b8-8354-4a7b-b5d1-0ead91b309b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA(지수이동평균) 추가하기\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "ecopro = fdr.DataReader('086520')\n",
    "close_prices = ecopro['Close']\n",
    "ema_50 = close_prices.ewm(span=50, adjust=False).mean()\n",
    "ecopro['ema_50'] = ema_50\n",
    "ema_12 = close_prices.ewm(span=12, adjust=False).mean()\n",
    "ecopro['ema_12'] = ema_12\n",
    "ema_26 = close_prices.ewm(span=26, adjust=False).mean()\n",
    "ecopro['ema_26'] = ema_26\n",
    "ema_200 = close_prices.ewm(span=200, adjust=False).mean()\n",
    "ecopro['ema_200'] = ema_200\n",
    "ecopro['MACD'] = ecopro['ema_12'] - ecopro['ema_26']\n",
    "ecopro['Signal Line'] = ecopro['MACD'].ewm(span=9, adjust=False).mean()\n",
    "# 결과 시각화\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(close_prices, label='Close Price', color='black')\n",
    "plt.plot(ema_50, label='10-day EMA', color='blue')\n",
    "plt.plot(ema_200, label='120-day EMA', color='red')\n",
    "plt.plot(ecopro['MACD'], label='MACD')\n",
    "plt.plot(ecopro['Signal Line'], label='Signal Line')\n",
    "plt.title('ECOPRO (086520) - Close Price and EMA')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "signals = [2]\n",
    "for i in range(1, len(ecopro)):\n",
    "        if ((ecopro['MACD'].iloc[i-1] < ecopro['Signal Line'].iloc[i-1]) and (ecopro['MACD'].iloc[i] > ecopro['Signal Line'].iloc[i])) or \\\n",
    "        ((ecopro['ema_50'].iloc[i-1] < ecopro['ema_200'].iloc[i-1]) and (ecopro['ema_50'].iloc[i] > ecopro['ema_200'].iloc[i])):\n",
    "            signals.append(1)  # 매수 신호\n",
    "        elif ((ecopro['MACD'].iloc[i-1] > ecopro['Signal Line'].iloc[i-1]) and (ecopro['MACD'].iloc[i] < ecopro['Signal Line'].iloc[i])) or \\\n",
    "        ((ecopro['ema_50'].iloc[i-1] > ecopro['ema_200'].iloc[i-1]) and (ecopro['ema_50'].iloc[i] < ecopro['ema_200'].iloc[i])):\n",
    "            signals.append(0)  # 매도 신호\n",
    "        else:\n",
    "            signals.append(2)  # 교차 없음\n",
    "ecopro['Signal'] = signals\n",
    "ecopro1 = ecopro.iloc[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1296c-8484-4f55-b375-98772c70784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 랜덤포레스트 모델 학습 및 평가\n",
    "# 특징 및 레이블 선택\n",
    "X = ecopro1[['ema_50', 'ema_12', 'ema_26', 'ema_200', 'MACD', 'Signal Line']]\n",
    "y = ecopro1['Signal']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# 랜덤포레스트 모델 학습\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a634cb-ecc9-4bfc-92df-bf7ecc5dbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 특징 및 레이블 선택\n",
    "X = ecopro1[['ema_50', 'ema_12', 'ema_26', 'ema_200', 'MACD', 'Signal Line']]\n",
    "y = ecopro1['Signal']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 랜덤포레스트 모델 학습 (OOB 점수 활성화)\n",
    "model = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "# OOB Score 확인\n",
    "print(f\"OOB Score: {model.oob_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523b7da-080f-4e6d-b8c3-a1d02acfb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 특징 및 레이블 선택\n",
    "X = ecopro1[['ema_50', 'ema_12', 'ema_26', 'ema_200', 'MACD', 'Signal Line']]\n",
    "y = ecopro1['Signal']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# SMOTE를 사용하여 오버샘플링\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 랜덤포레스트 모델 학습\n",
    "model = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "# OOB Score 확인\n",
    "print(f\"OOB Score: {model.oob_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21f12d-10a0-42d7-8106-b37c44e36acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 특징 및 레이블 선택\n",
    "X = ecopro1[['ema_50', 'ema_12', 'ema_26', 'ema_200', 'MACD', 'Signal Line']]\n",
    "y = ecopro1['Signal']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE를 사용하여 오버샘플링\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # 결정 트리의 개수\n",
    "    'max_depth': [None, 10, 20, 30],  # 트리의 최대 깊이\n",
    "    'min_samples_split': [2, 5, 10],  # 내부 노드를 분할하기 위한 최소 샘플 수\n",
    "    'min_samples_leaf': [1, 2, 4],  # 리프 노드에 있어야 하는 최소 샘플 수\n",
    "    'bootstrap': [True, False]  # 부트스트랩 샘플링 사용 여부\n",
    "}\n",
    "\n",
    "# RandomForestClassifier 인스턴스 생성\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV 인스턴스 생성\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# 모델 학습\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 최적의 하이퍼파라미터 및 모델\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 테스트 데이터로 예측 및 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "# OOB Score 확인\n",
    "print(f\"OOB Score: {best_model.oob_score_ if hasattr(best_model, 'oob_score_') else 'OOB Score not available'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9015f2-8d56-49f3-995e-cc5587ae1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# KOSPI 데이터에서 주식 코드 추출\n",
    "# KOSPI = fdr.StockListing('KOSPI')\n",
    "# stock_codes = KOSPI['Code'].tolist()\n",
    "\n",
    "# 사용하고 싶은 주식 코드의 수를 제한 \n",
    "# stock_codes = stock_codes[:100]\n",
    "# 분석할 주식 코드 목록\n",
    "stock_codes = ['041190', '015750', '215200', '095660', '025980', '099320', '215000', '290650', '101160', '006730', '023160', '043150',\n",
    "               '013030', '243070', '297890', '230360', '045100', '041830', '083450', '035890', '267980', '060250', '126700', '265520', \n",
    "               '018310', '050890', '035600', '051370', '148150', '054950', '211050', '299900', '078150', '118990', '108230', '950170', \n",
    "               '054450', '051500', '052400', '083310', '190510', '377450', '194700', '036890', '236200', '023760', '067280', '046440', \n",
    "               '123410', '136540', '214180', '092730', '036190', '023910', '452400', '298540', '091580', '079960', '009300', '023600', \n",
    "               '259630', '418470', '285490', '203650', '950190', '038110', '264450', '033290', '099440', '353810', '060560', '067900', \n",
    "               '092460', '100700', '382800', '066620', '066700', '013310', '124560', '332570', '021080', '137950', '069510', '215360',\n",
    "               '365330', '066590', '058630', '053700', '005990', '071200', '011560', '035610', '089850', '036630', '352090', '142210', \n",
    "               '043260', '042500', '302430', '019590', '038460', '417790', '111710', '040420', '234300', '059210', '024880', '065710', \n",
    "               '086670', '054040', '012790', '263690', '014200', '009780', '052790', '122310', '241520', '036640', '216050', '208140', \n",
    "               '007370', '036670', '038680', '339950', '158430', '048430', '094970', '115440', '155650', '024800', '241790', '082210', \n",
    "               '130580', '054930', '224110', '212560', '090410', '250000', '105760', '271830', '053270', '094840', '010240', '038010', \n",
    "               '039420', '092300', '019540', '227950', '100030', '440290', '122690', '067920', '204020', '088910', '263920', '263770', \n",
    "               '098120', '003310', '263020', '019770', '332370', '246690', '111870', '066360', '046310', '025880', '078590', '131090', \n",
    "               '340440', '267790', '290270', '099410', '052460', '020180', \n",
    "               '297570', '362990', '006920', '042940', '080470', '039310', '113810', '154040', '208350', '043590', '335870', '053060']\n",
    "\n",
    "# 빈 리스트를 만들어서 모든 주식 데이터를 통합할 준비\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# 각 주식 코드에 대해 데이터 불러오고 처리\n",
    "for code in stock_codes:\n",
    "    try:\n",
    "        df = fdr.DataReader(code).dropna()  # 데이터 불러오기 및 결측값 제거\n",
    "        \n",
    "        # 주식 데이터가 비어있지 않은 경우에만 처리\n",
    "        if not df.empty:\n",
    "            close_prices = df['Close'].values\n",
    "\n",
    "            # 지수 이동 평균 (EMA) 및 MACD 계산\n",
    "            ema_12 = pd.Series(close_prices).ewm(span=12, adjust=False).mean().values\n",
    "            ema_26 = pd.Series(close_prices).ewm(span=26, adjust=False).mean().values\n",
    "            ema_50 = pd.Series(close_prices).ewm(span=50, adjust=False).mean().values\n",
    "            ema_200 = pd.Series(close_prices).ewm(span=200, adjust=False).mean().values\n",
    "\n",
    "            macd = ema_12 - ema_26\n",
    "            signal_line = pd.Series(macd).ewm(span=9, adjust=False).mean().values\n",
    "\n",
    "            # 윈도우 사이즈와 예측 기간 설정\n",
    "            window_size = 10  # 윈도우 사이즈 (일수)\n",
    "            next_date = 1     # 예측 기간 (일수)\n",
    "\n",
    "            for i in range(len(close_prices) - window_size - next_date):\n",
    "                window = close_prices[i:i + window_size]\n",
    "                \n",
    "                # EMA 및 MACD 지표 추가\n",
    "                ema_window = ema_50[i:i + window_size]\n",
    "                macd_window = macd[i:i + window_size]\n",
    "                signal_window = signal_line[i:i + window_size]\n",
    "                \n",
    "                # 특성 벡터 생성\n",
    "                features = np.concatenate([ema_window, macd_window, signal_window])\n",
    "                \n",
    "                # Signals 계산\n",
    "                signals = [2]  # 초기값 (교차 없음)\n",
    "                for j in range(1, len(macd)):\n",
    "                    if ((macd[j-1] < signal_line[j-1]) and (macd[j] > signal_line[j])) or \\\n",
    "                       ((ema_50[j-1] < ema_200[j-1]) and (ema_50[j] > ema_200[j])):\n",
    "                        signals.append(1)  # 매수 신호\n",
    "                    elif ((macd[j-1] > signal_line[j-1]) and (macd[j] < signal_line[j])) or \\\n",
    "                         ((ema_50[j-1] > ema_200[j-1]) and (ema_50[j] < ema_200[j])):\n",
    "                        signals.append(0)  # 매도 신호\n",
    "                    else:\n",
    "                        signals.append(2)  # 교차 없음\n",
    "                \n",
    "                # 타겟 값을 현재 윈도우의 마지막 인덱스에 대해 설정\n",
    "                if i + window_size + next_date < len(signals):\n",
    "                    target = signals[i + window_size + next_date]\n",
    "                    X.append(features)\n",
    "                    Y.append(target)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing code {code}: {e}\")\n",
    "\n",
    "# X와 Y를 numpy 배열로 변환\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "862e4b10-b463-4f52-b5d9-bae9181f514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (89645, 30)\n",
      "Y shape: (89645,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 shape 출력\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'Y shape: {Y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db52c3d8-2fd3-4ff2-bb95-4be8fb115ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\campus4D046\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:40:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9196274192648781\n",
      "Confusion Matrix:\n",
      "[[    0     0   722]\n",
      " [    0     0   718]\n",
      " [    1     0 16488]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       722\n",
      "           1       0.00      0.00      0.00       718\n",
      "           2       0.92      1.00      0.96     16489\n",
      "\n",
      "    accuracy                           0.92     17929\n",
      "   macro avg       0.31      0.33      0.32     17929\n",
      "weighted avg       0.85      0.92      0.88     17929\n",
      "\n",
      "Sample Predictions:\n",
      "Actual: 2, Predicted: 2\n",
      "Actual: 2, Predicted: 2\n",
      "Actual: 2, Predicted: 2\n",
      "Actual: 2, Predicted: 2\n",
      "Actual: 2, Predicted: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\campus4D046\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\campus4D046\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\campus4D046\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할 (훈련 데이터와 테스트 데이터)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "# XGBoost 분류 모델 생성 및 학습\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic', \n",
    "    eval_metric='logloss', \n",
    "    learning_rate=0.1, \n",
    "    n_estimators=100, \n",
    "    max_depth=5, \n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# 테스트 데이터에 대해 예측 수행\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# 모델 평가\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "class_report = classification_report(Y_test, Y_pred)\n",
    "print(f'Classification Report:\\n{class_report}')\n",
    "\n",
    "# 예측 결과 확인\n",
    "print('Sample Predictions:')\n",
    "for i in range(min(5, len(Y_pred))):\n",
    "    print(f'Actual: {Y_test[i]}, Predicted: {Y_pred[i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "293865a1-4873-47d0-927e-1f633f4ef0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (89645, 30)\n",
      "Y shape: (89645,)\n",
      "Accuracy: 0.9162808857158793\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.00      0.00       722\n",
      "           1       0.00      0.00      0.00       774\n",
      "           2       0.92      1.00      0.96     16433\n",
      "\n",
      "    accuracy                           0.92     17929\n",
      "   macro avg       0.39      0.33      0.32     17929\n",
      "weighted avg       0.85      0.92      0.88     17929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 shape 출력\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'Y shape: {Y.shape}')\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=123)\n",
    "\n",
    "# XGBoost 모델 학습\n",
    "model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b0c9e-9d6f-487b-8085-ab7e29d77741",
   "metadata": {},
   "source": [
    "#### 예측했을 때 기업 식별자 코드도 같이 나오게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ce7661-3103-4c91-8276-d8380fbb9669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# 분석할 주식 코드 목록 (기업 식별자 추가)\n",
    "stock_codes = ['041190', '015750', '215200']\n",
    "\n",
    "# 빈 리스트를 만들어서 모든 주식 데이터를 통합할 준비\n",
    "X = []\n",
    "Y = []\n",
    "company_ids = []  # 기업 식별자를 저장할 리스트\n",
    "\n",
    "# 각 주식 코드에 대해 데이터 불러오고 처리\n",
    "for code in stock_codes:\n",
    "    try:\n",
    "        df = fdr.DataReader(code).dropna()  # 데이터 불러오기 및 결측값 제거\n",
    "        \n",
    "        # 주식 데이터가 비어있지 않은 경우에만 처리\n",
    "        if not df.empty:\n",
    "            close_prices = df['Close'].values\n",
    "\n",
    "            # 지수 이동 평균 (EMA) 및 MACD 계산\n",
    "            ema_12 = pd.Series(close_prices).ewm(span=12, adjust=False).mean().values\n",
    "            ema_26 = pd.Series(close_prices).ewm(span=26, adjust=False).mean().values\n",
    "            ema_50 = pd.Series(close_prices).ewm(span=50, adjust=False).mean().values\n",
    "            ema_200 = pd.Series(close_prices).ewm(span=200, adjust=False).mean().values\n",
    "\n",
    "            macd = ema_12 - ema_26\n",
    "            signal_line = pd.Series(macd).ewm(span=9, adjust=False).mean().values\n",
    "\n",
    "            # 기업 식별자를 원-핫 인코딩 형태로 생성\n",
    "            company_id = np.zeros(len(stock_codes))\n",
    "            company_id[stock_codes.index(code)] = 1\n",
    "\n",
    "            # 윈도우 사이즈와 예측 기간 설정\n",
    "            window_size = 10  # 윈도우 사이즈 (일수)\n",
    "            next_date = 1     # 예측 기간 (일수)\n",
    "\n",
    "            for i in range(len(close_prices) - window_size - next_date):\n",
    "                window = close_prices[i:i + window_size]\n",
    "                \n",
    "                # EMA 및 MACD 지표 추가\n",
    "                ema_window = ema_50[i:i + window_size]\n",
    "                macd_window = macd[i:i + window_size]\n",
    "                signal_window = signal_line[i:i + window_size]\n",
    "                \n",
    "                # 특성 벡터 생성 (기업 식별자 포함)\n",
    "                features = np.concatenate([ema_window, macd_window, signal_window, company_id])\n",
    "                \n",
    "                # Signals 계산\n",
    "                signals = [2]  # 초기값 (교차 없음)\n",
    "                for j in range(1, len(macd)):\n",
    "                    if ((macd[j-1] < signal_line[j-1]) and (macd[j] > signal_line[j])) or \\\n",
    "                       ((ema_50[j-1] < ema_200[j-1]) and (ema_50[j] > ema_200[j])):\n",
    "                        signals.append(1)  # 매수 신호\n",
    "                    elif ((macd[j-1] > signal_line[j-1]) and (macd[j] < signal_line[j])) or \\\n",
    "                         ((ema_50[j-1] > ema_200[j-1]) and (ema_50[j] < ema_200[j])):\n",
    "                        signals.append(0)  # 매도 신호\n",
    "                    else:\n",
    "                        signals.append(2)  # 교차 없음\n",
    "                \n",
    "                # 타겟 값을 현재 윈도우의 마지막 인덱스에 대해 설정\n",
    "                if i + window_size + next_date < len(signals):\n",
    "                    target = signals[i + window_size + next_date]\n",
    "                    X.append(features)\n",
    "                    Y.append(target)\n",
    "                    company_ids.append(stock_codes.index(code))  # 해당 데이터가 어떤 기업에 속하는지 기록\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing code {code}: {e}\")\n",
    "\n",
    "# X와 Y를 numpy 배열로 변환\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c8b5cd-c6b2-458b-a1e1-c145ac4830ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 (훈련 데이터와 테스트 데이터)\n",
    "X_train, X_test, Y_train, Y_test, company_ids_train, company_ids_test = train_test_split(X, Y, company_ids, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "# XGBoost 분류 모델 생성 및 학습\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # 다중 클래스 분류를 위한 설정\n",
    "    num_class=3,  # 세 가지 클래스 (0: 매도, 1: 매수, 2: 없음)\n",
    "    eval_metric='mlogloss', \n",
    "    learning_rate=0.1, \n",
    "    n_estimators=100, \n",
    "    max_depth=5, \n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# 테스트 데이터에 대해 예측 수행\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# 모델 평가\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "class_report = classification_report(Y_test, Y_pred)\n",
    "print(f'Classification Report:\\n{class_report}')\n",
    "\n",
    "# 예측 결과 확인 (기업 식별자 포함)\n",
    "print('Sample Predictions:')\n",
    "for i in range(min(5, len(Y_pred))):\n",
    "    actual_company = stock_codes[company_ids_test[i]]\n",
    "    print(f'Company: {actual_company}, Actual: {Y_test[i]}, Predicted: {Y_pred[i]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
